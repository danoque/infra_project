# Проектная работа
# Отказоустойчивое веб-приложение


### Минимальные требования для запуска проекта:

* Vagrant (Конфигурирует ВМ исходя из написанного кода)
* Ansible (Система управления конфигурациями)
* VirtualBox (или другой провайдер виртуализации)

### Общая структура:

schema_project2.png

### Описание инфраструктурных составляющих:

Общее количество нод в составе 17 штук распределяет на себя следующие роли:

1. Балансировщики нагрузки (http)
* VIP: 192.168.10.39
* Конфигурация Active-StandBy.
* Balancer1 IP: 192.168.10.40 - KeepAlived, HAProxy (Master)
* Balancer2 IP: 192.168.10.41 - KeepAlived, HAProxy (Slave)

2. Веб-сервера - отдача статики и отправка посредством балансировки на сервера приложения
* Web1 IP: 192.168.10.42 - Nginx, служба GlusterFS для монтирования директории с файлами сайта (Master)
* Web2 IP: 192.168.10.43 - Nginx, служба GlusterFS для монтирования директории с файлами сайта (Master)

3. Кластерная файловая система - хранилище файлов сайта
* GlusterFS1 IP: 192.168.10.44 - GlusterFS (Master)
* GlusterFS2 IP: 192.168.10.45 - GlusterFS (Master)
* GlusterFS3 IP: 192.168.10.46 - GlusterFS (Master)

4. Сервера приложений - исполнение PHP кода, проксирование SQL запросов к серверам БД, отправка на сервера Redis (балансировщик) сессии и чтение оттуда
* Backend1 IP: 192.168.10.47 - PHP, служба GlusterFS для монтирования директории с файлами, ProxySQL (Master)
* Backend2 IP: 192.168.10.48 - PHP, служба GlusterFS для монтирования директории с файлами ProxySQL (Master)

5. Балансировщики нагрузки - Redis, MySQL
* VIP: 192.168.10.53  - проксирование Redis запросов с серверов приложений, резерв для проксирования SQL через HAProxy. Конфигурация Active-StandBy.
* Balancer3 IP: 192.168.10.52 - KeepAlived, HAProxy (Master)
* Balancer4 IP: 192.168.10.54 - KeepAlived, HAProxy (Slave)

6. Сервера NoSQL БД Redis - хранение сессий и кэширования (возможно использование для кэширования результатов SQL запросов, ускоряет загрузку сайта примерно в 2 раза. Для этого используется специальное расширение в самом Wordpress, требует доолнительной настройки). Sentinel необходим за контролем и переключением мастера и слэйва. Необходимо использовать нечетное количество нод для достижения кворума. В данном случае решение о переключении мастера принимают 2 ноды Sentinel.
* Redis1 IP: 192.168.10.49 - Redis, Sentinel (Master)
* Redis2 IP: 192.168.10.50 - Redis, Sentinel (Slave)
* Redis3 IP: 192.168.10.51 - Redis, Sentinel (Slave) 

7. Сервера БД - Percona XtraDB - наиболее стабильный форк MySQL, решено большое количество вопросов в плане стабильности и возможностей резервного копирования.Необходимо использовать нечетное количество серверов в режиме мультимастер.
* Percona1 IP: 192.168.10.55 - Percona MySQL (Master)
* Percona2 IP: 192.168.10.56 - Percona MySQL (Master)
* Percona3 IP: 192.168.10.57 - Percona MySQL (Master)

На веб-серверах и серверах приложения настроены одинаковые пути до директории сайта - ```/mnt/gluster/```.

### Состав ПО и проекта:

Главная задача, решённая по ходу выполнения проекта, - создать отказоустойчивый кластер на всех уровнях работы приложения. В случае выхода из строя какой-либо ноды сервис не теряет работоспособное состояние. Для решения поставленной задачи применялось следующее ПО:

1. KeepAlived - следит за состоянием приложения HAProxy, а также за состоянием другого хоста (в случае Slave). Использует общий виртуальный IP адрес, который переходит на ту ноду, которая осталась в рабочем состоянии, либо на ту ноду, на которой работает приложение HAProxy, необходимое для проксирования запросов.

2. HAProxy - проксирует пользовательские запросы. В проекте используется http, redis, MySQL проксирование (на balancer3 и balancer4 как запасное MySQL проксирование).

haproxy-web.png

3. Nginx - высокопроизводительный веб-сервер. Выделен в обособленую группу серверов, для более эффективного размазывания нагрузки. Используется сжатие трафика, следовательно присутствуют дополнительные траты ресурса процессора.

4. Интерпретатор PHP 7.2 - установлен на отдельных серверах приложений

5. ProxySQL - проксирование SQL запросов по группам серверов (группы записи, группы чтения, запасная группа записи). Следить за доступностью SQL серверов и автоматически выводит и вводит в строй. Имеет свой командный интерфейс управления (аналогичен работе с обычным SQL инстансом). Умеет определять тип запроса и отправлять на нужные сервера. В данном случае используется 1 сервер для записи, несмотря на то что у нас в схеме 3 мастер сервера. Сделано для того чтобы избежать взаимных блокировок (DeadLock). В данном проекте ProxySQL является основным проксирующим средством SQL запросов.

proxysql.png

proxysql2.png

6. GlusterFS - кластерная файловая система. Образует файловый кластер для файлового хранилища (где хранятся файлы сайта). Все веб-сервера и сервера приложений имеют доступ к файловому хранилищу для того чтобы сайт работал. На веб-серверах и серверах приложений установлен клиент GlusterFS.

gluster.png

7. Redis 6 - NoSQL БД для хранения сессий и кэширования данных. В данном случае используется 1 мастер и 2 слэйва. Переключение происходит в случае падения мастера, за этим следит Sentinel. Храние данных в ОЗУ, за счет чего быстро записывает и отдает данные. Периодический сброс данных на диск.

redis-cli.png

sentinel.png

8. Percona Multi-Master MySQL - сервера БД, которые хранят данные сайта в таблицах. 

percona.png

Balancer3 и Balancer4 также могут участвовать в проксировании SQL запросов, однако HAProxy не умеет понимать тип SQL запроса. Проксирование идет исходя из доступности нод.
Также же на этих нодах проксируется Redis, в данном случае HAProxy определяет какая из нод является мастером и пишет только на мастер.
Как видно на изображении ниже, 2 Slave сервера redis помечены красным, это нормально, так как на них не отправляются запросы. Запись может выполняться только на мастер сервер. Также видно что настроено MySQL проксирование (как резервное, а также для демонстрации возможностей), исходя из настроек весов, запросы отправляются всегда на один сервер. 

haproxy-redis.png

### Веб-интерфейс проекта:

ProxySQL использует порт 6033 для проксирования запросов сайта, и порт 6032 для администрирования.

wp.png

На слайде ниже предлагается создать файл конфигурации для связи с БД. СОздание будет не безопасным, безопаснее вручную создать такой файл с правами 750.

wp3.png
wp2.png

### Для запуска проекта необходимо выпонить следующие шаги, Необходимо соблюдать порядок запуска нод:

```
vagrant up percona1 percona2 percona3 redis1 redis2 redis3 balancer3 balancer4 glusterfs1 glusterfs2 glusterfs3
export ANSIBLE_CONFIG=$(pwd)/ansible-gluster/ansible.cfg
ansible-playbook ansible-gluster/provision.yml
vagrant up backend1 backend2 web1 web2 balancer1 balancer2
```

